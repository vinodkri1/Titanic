{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport sklearn.tree\nimport sklearn.ensemble\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T01:16:53.782352Z","iopub.execute_input":"2022-05-24T01:16:53.782716Z","iopub.status.idle":"2022-05-24T01:16:53.790858Z","shell.execute_reply.started":"2022-05-24T01:16:53.782682Z","shell.execute_reply":"2022-05-24T01:16:53.789934Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#Load training, testing, and validation data\ndata = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata = data.sample(frac=1).reset_index(drop=True)\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T23:24:11.717061Z","iopub.execute_input":"2022-05-23T23:24:11.717421Z","iopub.status.idle":"2022-05-23T23:24:11.747919Z","shell.execute_reply.started":"2022-05-23T23:24:11.717388Z","shell.execute_reply":"2022-05-23T23:24:11.746961Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Split into train and validation\nN_TRAIN = 601\ntrain_data = data.iloc[0:600]\nvalid_data = data.iloc[601:-1]\ntrain_data.head(15)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T23:24:13.527091Z","iopub.execute_input":"2022-05-23T23:24:13.527440Z","iopub.status.idle":"2022-05-23T23:24:13.559866Z","shell.execute_reply.started":"2022-05-23T23:24:13.527411Z","shell.execute_reply":"2022-05-23T23:24:13.559224Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Data Cleaning\n#Drop columns with too many null values\nfor col_name in train_data.columns:\n    num_null = train_data[col_name].isnull().sum()\n    if num_null > 100:\n        train_data.drop(col_name, axis = 1, inplace = True)\n        valid_data.drop(col_name, axis = 1, inplace = True)\n        test_data.drop(col_name, axis = 1, inplace = True)\n\n#Drop rows with too many null values\ndrop_row_list = []\nfor row_num in range(N_TRAIN-1):\n    row = train_data.iloc[row_num]\n    num_null = row.isnull().sum()\n    if num_null > 5:\n        #Drop row\n        drop_row_list.append(row_num)\nprint(drop_row_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T23:24:15.620197Z","iopub.execute_input":"2022-05-23T23:24:15.620777Z","iopub.status.idle":"2022-05-23T23:24:15.829998Z","shell.execute_reply.started":"2022-05-23T23:24:15.620742Z","shell.execute_reply":"2022-05-23T23:24:15.829066Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumeric_cols = list(train_data.select_dtypes(include=numerics).columns)\nif 'PassengerId' in numeric_cols:\n    numeric_cols.remove('PassengerId')\nif 'Survived' in numeric_cols:\n    numeric_cols.remove('Survived')\n\ncategorical_cols = []\nfor col_name in train_data.columns:\n    if col_name not in numeric_cols and col_name != 'PassengerId' and col_name != 'Survived' and col_name != 'Name':\n        categorical_cols.append(col_name)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T23:41:46.758570Z","iopub.execute_input":"2022-05-23T23:41:46.758887Z","iopub.status.idle":"2022-05-23T23:41:46.766701Z","shell.execute_reply.started":"2022-05-23T23:41:46.758857Z","shell.execute_reply":"2022-05-23T23:41:46.765643Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Fill null values with something\ntrain_data.isnull().sum().head(15)\ntrain_data['Embarked'].value_counts()\ntrain_data['Embarked'].fillna('S', inplace = True)\ntest_data['Embarked'].fillna('S', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T01:01:31.683164Z","iopub.execute_input":"2022-05-24T01:01:31.683524Z","iopub.status.idle":"2022-05-24T01:01:31.693940Z","shell.execute_reply.started":"2022-05-24T01:01:31.683494Z","shell.execute_reply":"2022-05-24T01:01:31.692794Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#train_data['MSSubClass'].head()\nfor col_name in numeric_cols:\n    print(col_name, \n          train_data[train_data['Survived'] == 0][col_name].mean(), \n          train_data[train_data['Survived'] == 0][col_name].std(),\n          train_data[train_data['Survived'] == 1][col_name].mean(),\n          train_data[train_data['Survived'] == 1][col_name].std())","metadata":{"execution":{"iopub.status.busy":"2022-05-23T23:41:51.886058Z","iopub.execute_input":"2022-05-23T23:41:51.886432Z","iopub.status.idle":"2022-05-23T23:41:51.909696Z","shell.execute_reply.started":"2022-05-23T23:41:51.886399Z","shell.execute_reply":"2022-05-23T23:41:51.908803Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#For each categorical column, do a bar chart\nfor col_name in categorical_cols:\n    labels = list(train_data[col_name].unique())\n    means = {}\n    for label in labels:\n        means[label] = train_data[train_data[col_name] == label]['Survived'].mean()\n    print(col_name, means)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T23:41:54.189816Z","iopub.execute_input":"2022-05-23T23:41:54.190378Z","iopub.status.idle":"2022-05-23T23:41:54.516834Z","shell.execute_reply.started":"2022-05-23T23:41:54.190331Z","shell.execute_reply":"2022-05-23T23:41:54.515957Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(numeric_cols)\nnumeric_cols.remove('SibSp')\ncategorical_cols.append('SibSp')\nnumeric_cols.remove('Parch')\ncategorical_cols.append('Parch')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T00:10:28.826496Z","iopub.execute_input":"2022-05-24T00:10:28.826831Z","iopub.status.idle":"2022-05-24T00:10:28.831592Z","shell.execute_reply.started":"2022-05-24T00:10:28.826802Z","shell.execute_reply":"2022-05-24T00:10:28.830773Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Random forest regressor needs numerical columns for some strange reason\ndef numericalize(col_name, df):\n    set_of_values = set()\n    for value in df[col_name].values:\n        set_of_values.add(value)\n    index = 0\n    my_dict = {}\n    for value in set_of_values:\n        my_dict[value] = index\n        index = index+1\n    return df[col_name].replace(to_replace = my_dict)\n\ncategorical_cols_num = []\nfor col in categorical_cols:\n    categorical_cols_num.append(col + '_num')\n    train_data[col + '_num'] = numericalize(col, train_data)\n    valid_data[col + '_num'] = numericalize(col, valid_data)\n    test_data[col + '_num'] = numericalize(col, test_data)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T00:15:42.590475Z","iopub.execute_input":"2022-05-24T00:15:42.591110Z","iopub.status.idle":"2022-05-24T00:15:42.728800Z","shell.execute_reply.started":"2022-05-24T00:15:42.591074Z","shell.execute_reply":"2022-05-24T00:15:42.727638Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Implement scaling features, first convert to float\n#Helps for some models, not sure about XGBRegressor\nfor col_name in numeric_cols:\n    train_data[col_name] = train_data[col_name].astype(float)\n    valid_data[col_name] = valid_data[col_name].astype(float)\n    test_data[col_name] = test_data[col_name].astype(float)\n    mean_value = train_data[col_name].mean()\n    std_value = train_data[col_name].std()\n    train_data[col_name] = (train_data[col_name]-mean_value)/std_value\n    valid_data[col_name] = (valid_data[col_name]-mean_value)/std_value\n    test_data[col_name] = (test_data[col_name]-mean_value)/std_value","metadata":{"execution":{"iopub.status.busy":"2022-05-24T00:17:22.793446Z","iopub.execute_input":"2022-05-24T00:17:22.793976Z","iopub.status.idle":"2022-05-24T00:17:22.807239Z","shell.execute_reply.started":"2022-05-24T00:17:22.793927Z","shell.execute_reply":"2022-05-24T00:17:22.806367Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#Train random forest and fit results\ndtree = sklearn.ensemble.RandomForestClassifier(n_estimators = 250, max_depth=3, random_state = 8)\ndtree.fit(train_data[numeric_cols + categorical_cols_num], train_data[\"Survived\"])\nprint(dtree.score(valid_data[numeric_cols + categorical_cols_num], valid_data['Survived']))\n\nxgbtree = xgb.XGBClassifier().fit(train_data[numeric_cols + categorical_cols_num], train_data['Survived'])\nprint(xgbtree.score(valid_data[numeric_cols + categorical_cols_num], valid_data['Survived']))\n\nlogistic = LogisticRegression()\nlogistic.fit(train_data[numeric_cols], train_data[\"Survived\"])\nprint(logistic.score(valid_data[numeric_cols], valid_data['Survived']))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T01:17:55.277953Z","iopub.execute_input":"2022-05-24T01:17:55.278327Z","iopub.status.idle":"2022-05-24T01:17:55.761862Z","shell.execute_reply.started":"2022-05-24T01:17:55.278293Z","shell.execute_reply":"2022-05-24T01:17:55.760308Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\ntest_data.isna().sum().head(12)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T01:03:27.479800Z","iopub.execute_input":"2022-05-24T01:03:27.480127Z","iopub.status.idle":"2022-05-24T01:03:27.491587Z","shell.execute_reply.started":"2022-05-24T01:03:27.480097Z","shell.execute_reply":"2022-05-24T01:03:27.490405Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"best_model = xgbtree\ntest_data['Survived'] = best_model.predict(test_data[numeric_cols + categorical_cols_num])\nans = test_data[['PassengerId', 'Survived']]\nans.to_csv('tuned_output.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-24T01:18:16.328305Z","iopub.execute_input":"2022-05-24T01:18:16.328798Z","iopub.status.idle":"2022-05-24T01:18:16.343267Z","shell.execute_reply.started":"2022-05-24T01:18:16.328767Z","shell.execute_reply":"2022-05-24T01:18:16.341987Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"print(best_num_classif)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T08:23:58.79122Z","iopub.execute_input":"2021-08-14T08:23:58.791564Z","iopub.status.idle":"2021-08-14T08:23:58.797083Z","shell.execute_reply.started":"2021-08-14T08:23:58.791532Z","shell.execute_reply":"2021-08-14T08:23:58.795842Z"},"trusted":true},"execution_count":null,"outputs":[]}]}